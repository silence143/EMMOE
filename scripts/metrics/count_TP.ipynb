{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_execution_history(history_string):\n",
    "    history_string = history_string.replace(\"Historical Execution: \", \"\")\n",
    "    historty_splits = re.split(r'(\\(fail\\)|\\(success\\))\\s', history_string)\n",
    "\n",
    "    parsed_steps = []\n",
    "\n",
    "    for i in range(0, len(historty_splits)-1, 2):\n",
    "        result = 'success' if 'success' in historty_splits[i+1] else 'fail'\n",
    "        action_parts = re.sub(r'\\(.*?\\)', '', historty_splits[i], 1).strip().lstrip('[').rstrip(']').split(',')\n",
    "        \n",
    "        parsed_step = [\n",
    "            action_parts[0].strip(),\n",
    "            action_parts[1].strip().lower() if len(action_parts) > 1 else \"None\",\n",
    "            action_parts[2].strip().lower() if len(action_parts) > 2 else \"None\",\n",
    "            result\n",
    "        ]\n",
    "        parsed_steps.append(parsed_step)\n",
    "\n",
    "    return parsed_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"Qwen2VL\"\n",
    "exp_path = os.path.join(\"exp\", exp_name)\n",
    "\n",
    "eval_list = []\n",
    "\n",
    "for index in os.listdir(exp_path):\n",
    "    for i in range(1, 4):\n",
    "        conv_path = os.path.join(exp_path, index, f\"{i}/conversation.json\")\n",
    "        if not os.path.exists(conv_path):\n",
    "            continue\n",
    "        with open(conv_path, 'r') as file:\n",
    "            conv = json.load(file)\n",
    "\n",
    "        exe_dict = {}\n",
    "        exe_dict[\"index\"] = index\n",
    "        exe_dict[\"times\"] = i \n",
    "\n",
    "        add_end = 0\n",
    "        if \"End\" in conv[-1]:\n",
    "            add_end = 1\n",
    "        history = conv[-1].split('\\n')[3]\n",
    "        exe_dict[\"history\"] = parse_execution_history(history)\n",
    "        if add_end == 1:\n",
    "            exe_dict['history'].append([\"End\", \"None\", \"None\", \"success\"])\n",
    "        exe_dict['step_len'] = len(exe_dict['history'])\n",
    "        eval_list.append(exe_dict)\n",
    "\n",
    "print(len(eval_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_name_mapping():\n",
    "        with open('hab-mobile-manipulation/name_dict.txt', 'r') as file:\n",
    "            content = file.read()\n",
    "        lines = content.split('\\n')\n",
    "        print(lines[-1])\n",
    "        \n",
    "        name_dict = {}\n",
    "        for i in range(0, len(lines), 3):\n",
    "            value = lines[i].strip().strip(':')\n",
    "            key = lines[i + 1].strip()\n",
    "            keys = key.split('/')\n",
    "            for i in keys:\n",
    "                name_dict[i] = value\n",
    "\n",
    "        return name_dict\n",
    "    # mapping item name\n",
    "mapping_dict = load_name_mapping()\n",
    "\n",
    "def match_action(action, keypoint, mapping_dict):\n",
    "        if action[3] != 'success':\n",
    "               return False\n",
    "\n",
    "        key_action = [element.strip() for element in keypoint.strip('[').strip(']').split(',')]\n",
    "        if len(key_action) == 2:\n",
    "            key_action.append(\"None\")\n",
    "        if action[0] == key_action[0]:\n",
    "                if key_action[0] == \"End\":\n",
    "                    return True\n",
    "                obj1 = mapping_dict[action[1]]\n",
    "                obj2 = mapping_dict[key_action[1]]\n",
    "                if obj1 == obj2:\n",
    "                       obj11 = \"None\" if action[2] == \"None\" else mapping_dict[action[2]]\n",
    "                       obj22 = \"None\" if key_action[2] == \"None\" else mapping_dict[key_action[2]]\n",
    "                       if obj11 == obj22:\n",
    "                              return True\n",
    "        return False\n",
    "\n",
    "def match(list1, list2):\n",
    "    if len(list2) == 0:\n",
    "        return 0\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    \n",
    "    while index1 < len(list1) and index2 < len(list2):\n",
    "        \n",
    "        if match_action(list1[index1], list2[index2], mapping_dict):\n",
    "            index2 += 1\n",
    "        index1 += 1\n",
    "    \n",
    "    \n",
    "    return index2 / len(list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eval_node in eval_list:\n",
    "    task_id = eval_node['index']\n",
    "    history = eval_node['history']\n",
    "\n",
    "    if 1 <= int(task_id) <= 90:\n",
    "        data_dir = \"EMMOE-100/data/train\"\n",
    "    else:\n",
    "        data_dir = \"EMMOE-100/data/test\"\n",
    "\n",
    "    with open(os.path.join(data_dir, str(task_id), \"keypath.json\"), 'r') as file:\n",
    "        keypaths = json.load(file)\n",
    "\n",
    "    tp = 0\n",
    "    for keypath in keypaths:\n",
    "        tp_tmp = match(history, keypath)\n",
    "        tp = max(tp_tmp, tp)\n",
    "            \n",
    "    eval_node['tp'] = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnt = 0\n",
    "test_cnt = 0\n",
    "train_success = 0\n",
    "test_success = 0\n",
    "train_tp = 0\n",
    "test_tp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in eval_list:\n",
    "    task_id = node['index']\n",
    "    if 1 <= int(task_id) <= 90:\n",
    "        train_cnt += 1\n",
    "        train_tp += node['tp']\n",
    "        if node['tp'] == 1:\n",
    "            train_success += 1\n",
    "    else:\n",
    "        test_cnt += 1\n",
    "        test_tp += node['tp']\n",
    "        if node['tp'] == 1:\n",
    "            test_success += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg_tp = train_tp / train_cnt\n",
    "test_avg_tp = test_tp / test_cnt\n",
    "train_sr = train_success / train_cnt\n",
    "test_sr = test_success / test_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011111111111111112 0.15784391534391543 0.0 0.23452380952380958\n"
     ]
    }
   ],
   "source": [
    "print(train_sr, train_avg_tp, test_sr, test_avg_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.16551190476190483\n"
     ]
    }
   ],
   "source": [
    "all_sr = (train_success + test_success)/(train_cnt + test_cnt)\n",
    "all_tp = (train_tp + test_tp)/(train_cnt + test_cnt)\n",
    "print(all_sr,all_tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
