{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"MiniCPM\"\n",
    "round = 1\n",
    "episode_id = 1\n",
    "flag = 'all'\n",
    "task_type = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag == 'train':\n",
    "    ran = range(1,91)\n",
    "elif flag == 'test':\n",
    "    ran = range(91,101)\n",
    "else:\n",
    "    ran = range(1,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = {}\n",
    "task_list['typical'] = [2, 7, 9, 19, 24, 27, 28, 31, 46, 47, 49, 60, 61, 70, 91, 92]\n",
    "task_list['long-horizon'] = [1, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "task_list['open-ended'] = [20, 22, 44, 69, 76, 77, 96, 97, 98]\n",
    "task_list['logical'] = [1, 2, 3, 4, 12, 14, 15, 17, 18, 19, 20, 23, 26, 27, 34, 37, 38, 40, 42, 43, 44, 45, 52, 55, 56, 57, 59, 62, 64, 68, 69, 71, 72, 73, 75, 76, 77, 80, 81, 83, 84, 85, 86, 87, 88, 94, 96, 98, 100]\n",
    "task_list['human style'] = [1, 2, 3, 4, 5, 6, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 49, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 64, 66, 68, 69, 71, 72, 73, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 91, 94, 98, 96, 97, 100]\n",
    "if task_type != 'all':\n",
    "    ran = task_list[task_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_execution_history(history_string):\n",
    "    history_string = history_string.replace(\"Historical Execution: \", \"\")\n",
    "    historty_splits = re.split(r'(\\(fail\\)|\\(success\\))\\s', history_string)\n",
    "\n",
    "    parsed_steps = []\n",
    "\n",
    "    for i in range(0, len(historty_splits)-1, 2):\n",
    "        result = 'success' if 'success' in historty_splits[i+1] else 'fail'\n",
    "        action_parts = re.sub(r'\\(.*?\\)', '', historty_splits[i], 1).strip().lstrip('[').rstrip(']').split(',')\n",
    "        \n",
    "        parsed_step = [\n",
    "            action_parts[0].strip(),\n",
    "            action_parts[1].strip().lower() if len(action_parts) > 1 else \"None\",\n",
    "            action_parts[2].strip().lower() if len(action_parts) > 2 else \"None\",\n",
    "            result\n",
    "        ]\n",
    "        parsed_steps.append(parsed_step)\n",
    "\n",
    "    return parsed_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_list_gen(exp_name, round):\n",
    "\n",
    "    exp_path = os.path.join(\"exp\", exp_name)\n",
    "\n",
    "    eval_list = []\n",
    "\n",
    "    for index in os.listdir(exp_path):\n",
    "        conv_path = os.path.join(exp_path, index, f\"{round}/conversation.json\")\n",
    "        if not os.path.exists(conv_path):\n",
    "            continue\n",
    "\n",
    "        with open(conv_path, 'r') as file:\n",
    "            conv = json.load(file)  \n",
    "        exe_dict = {}\n",
    "        exe_dict[\"index\"] = int(index) \n",
    "        exe_dict[\"step_len\"] = len(conv)\n",
    "\n",
    "        history = conv[-1].split('\\n')[3]\n",
    "        exe_dict[\"history\"] = parse_execution_history(history)\n",
    "        eval_list.append(exe_dict) \n",
    "\n",
    "    eval_list = sorted(eval_list, key=lambda x: x[\"index\"])\n",
    "    print(len(eval_list))\n",
    "    return eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = eval_list_gen(exp_name,round)\n",
    "eval_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_success_list_gen(exp_name,round):\n",
    "\n",
    "    exp_path = os.path.join(\"exp\", exp_name)\n",
    "\n",
    "    eval_success_list = []\n",
    "\n",
    "    for index in os.listdir(exp_path):\n",
    "        conv_path = os.path.join(exp_path, index, f\"{round}/conversation.json\")\n",
    "        if not os.path.exists(conv_path):\n",
    "            continue\n",
    "\n",
    "        with open(conv_path, 'r') as file:\n",
    "            conv = json.load(file)\n",
    "        if 'End' in conv[-1]:   \n",
    "            exe_dict = {}\n",
    "            exe_dict[\"index\"] = int(index) \n",
    "            exe_dict[\"step_len\"] = len(conv)\n",
    "\n",
    "            history = conv[-1].split('\\n')[3]\n",
    "            exe_dict[\"history\"] = parse_execution_history(history)\n",
    "            exe_dict[\"history\"].append([\"End\", \"None\", \"None\", \"success\"])\n",
    "            eval_success_list.append(exe_dict)\n",
    "\n",
    "    eval_success_list = sorted(eval_success_list, key=lambda x: x[\"index\"])\n",
    "    print(len(eval_success_list))\n",
    "\n",
    "    return eval_success_list\n",
    "\n",
    "def load_name_mapping():\n",
    "        with open('hab-mobile-manipulation/name_dict.txt', 'r') as file:\n",
    "            content = file.read()\n",
    "        lines = content.split('\\n')\n",
    "        print(lines[-1])\n",
    "        \n",
    "        name_dict = {}\n",
    "        for i in range(0, len(lines), 3):\n",
    "            value = lines[i].strip().strip(':')\n",
    "            key = lines[i + 1].strip()\n",
    "            keys = key.split('/')\n",
    "            for i in keys:\n",
    "                name_dict[i] = value\n",
    "\n",
    "        return name_dict\n",
    "    # mapping item name\n",
    "mapping_dict = load_name_mapping()\n",
    "\n",
    "def match_action(action, keypoint, mapping_dict):\n",
    "        #print(keypoint)\n",
    "        if action[3] == 'fail':\n",
    "               return False\n",
    "\n",
    "        key_action = [element.strip() for element in keypoint.strip('[').strip(']').split(',')]\n",
    "        if len(key_action) == 2:\n",
    "            key_action.append(\"None\")\n",
    "        if action[0] == key_action[0]:\n",
    "                if key_action[0] == \"End\":\n",
    "                    return True\n",
    "                obj1 = mapping_dict[action[1]]\n",
    "                obj2 = mapping_dict[key_action[1]]\n",
    "                if obj1 == obj2:\n",
    "                       obj11 = \"None\" if action[2] == \"None\" else mapping_dict[action[2]]\n",
    "                       obj22 = \"None\" if key_action[2] == \"None\" else mapping_dict[key_action[2]]\n",
    "                       if obj11 == obj22:\n",
    "                              return True\n",
    "        return False\n",
    "def match(list1, list2):\n",
    "    if len(list2) == 0:\n",
    "        return False\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    \n",
    "    while index1 < len(list1) and index2 < len(list2):\n",
    "        if match_action(list1[index1], list2[index2], mapping_dict):\n",
    "            index2 += 1\n",
    "        index1 += 1\n",
    "    \n",
    "    return index2 == len(list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_success_list = eval_success_list_gen(exp_name,round)\n",
    "eval_success_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_list = []\n",
    "\n",
    "for eval_success in eval_success_list:\n",
    "    task_id = eval_success['index']\n",
    "    history = eval_success['history']\n",
    "    if 1 <= int(task_id) <= 90:\n",
    "        data_dir = \"EMMOE-100/data/train\"\n",
    "    else:\n",
    "        data_dir = \"EMMOE-100/data/test\"\n",
    "\n",
    "    with open(os.path.join(data_dir, str(task_id), \"keypath.json\"), 'r') as file:\n",
    "        keypaths = json.load(file)\n",
    "\n",
    "    for keypath in keypaths:\n",
    "        if match(history, keypath):\n",
    "            success_list.append(task_id)\n",
    "            break\n",
    "\n",
    "print(len(success_list))\n",
    "success_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in success_list:\n",
    "    if i in ran:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dataset_path():\n",
    "    path_count = 0\n",
    "    for test_scene in os.listdir('EMMOE-100/data/test'):\n",
    "        with open(f'EMMOE-100/data/test/{test_scene}/info.txt', 'r') as f:\n",
    "            info = f.read()\n",
    "            subtaskss = info.split('\\n')\n",
    "            subtasks = [  i for i in subtaskss if 'Subtask' in i]\n",
    "            path_count += len(subtasks)\n",
    "            # print(len(subtasks))\n",
    "    for train_scene in os.listdir('EMMOE-100/data/train'):\n",
    "        with open(f'EMMOE-100/data/train/{train_scene}/info.txt', 'r') as f:\n",
    "            info = f.read()\n",
    "            subtaskss = info.split('\\n')\n",
    "            subtasks = [  i for i in subtaskss if 'Subtask' in i]\n",
    "            path_count += len(subtasks)\n",
    "    return path_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_length_weighted(episode_id,eval_list):\n",
    "    for aval in eval_list:\n",
    "        if episode_id == aval['index']:\n",
    "            real_path_count = aval['step_len']\n",
    "    if episode_id > 90:\n",
    "        temp = 'test'\n",
    "    else:\n",
    "        temp = 'train'\n",
    "    with open(f'EMMOE-100/data/{temp}/{episode_id}/info.txt', 'r') as f:\n",
    "        info = f.read()\n",
    "        subtaskss = info.split('\\n')\n",
    "        subtasks = [  i for i in subtaskss if 'Subtask' in i]\n",
    "        dataset_path_count = len(subtasks)\n",
    "    return dataset_path_count/max(real_path_count,dataset_path_count), real_path_count, dataset_path_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = path_length_weighted(episode_id,eval_list)\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_list_gen_ran(exp_name, round,ran):\n",
    "\n",
    "    exp_path = os.path.join(\"/data1/tct_data/Video-LLaVA/exp\", exp_name)\n",
    "\n",
    "    eval_list = []\n",
    "\n",
    "    for index in os.listdir(exp_path):\n",
    "        conv_path = os.path.join(exp_path, index, f\"{round}/conversation.json\")\n",
    "        if not os.path.exists(conv_path):\n",
    "            continue\n",
    "        if int(index) in ran:\n",
    "            with open(conv_path, 'r') as file:\n",
    "                conv = json.load(file)  \n",
    "            exe_dict = {}\n",
    "            exe_dict[\"index\"] = int(index) \n",
    "            exe_dict[\"step_len\"] = len(conv)\n",
    "\n",
    "            history = conv[-1].split('\\n')[3]\n",
    "            exe_dict[\"history\"] = parse_execution_history(history)\n",
    "            eval_list.append(exe_dict) \n",
    "\n",
    "    eval_list = sorted(eval_list, key=lambda x: x[\"index\"])\n",
    "    print(len(eval_list))\n",
    "    return eval_list\n",
    "def plwsr(exp_name,ran):\n",
    "    plw_total = 0\n",
    "    task_total = 0\n",
    "    for round in range(1,4):\n",
    "        eval_list = eval_list_gen_ran(exp_name,round,ran)\n",
    "        eval_success_list = eval_success_list_gen(exp_name,round)\n",
    "        \n",
    "        success_list = []\n",
    "        for eval_success in eval_success_list:\n",
    "            task_id = eval_success['index']\n",
    "            history = eval_success['history']\n",
    "            if 1 <= int(task_id) <= 90:\n",
    "                data_dir = \"/data1/tct_data/Video-LLaVA/HomieBot/data/train\"\n",
    "            else:\n",
    "                data_dir = \"/data1/tct_data/Video-LLaVA/HomieBot/data/test\"\n",
    "\n",
    "            with open(os.path.join(data_dir, str(task_id), \"keypath.json\"), 'r') as file:\n",
    "                keypaths = json.load(file)\n",
    "\n",
    "            for keypath in keypaths:\n",
    "                if match(history, keypath):\n",
    "                    success_list.append(task_id)\n",
    "                    break\n",
    "\n",
    "        print(len(success_list))\n",
    "        for succ in success_list:\n",
    "            if succ in ran:\n",
    "                plw, _, _ = path_length_weighted(succ,eval_list)\n",
    "                plw_total += plw\n",
    "        task_total += len(eval_list)\n",
    "\n",
    "    return plw_total/task_total\n",
    "def sr(exp_name,ran):\n",
    "    sr_total = 0\n",
    "    task_total = 0\n",
    "    for round in range(1,4):\n",
    "        eval_list = eval_list_gen_ran(exp_name,round,ran)\n",
    "        eval_success_list = eval_success_list_gen(exp_name,round)\n",
    "        \n",
    "        success_list = []\n",
    "        for eval_success in eval_success_list:\n",
    "            task_id = eval_success['index']\n",
    "            history = eval_success['history']\n",
    "            if 1 <= int(task_id) <= 90:\n",
    "                data_dir = \"/data1/tct_data/Video-LLaVA/HomieBot/data/train\"\n",
    "            else:\n",
    "                data_dir = \"/data1/tct_data/Video-LLaVA/HomieBot/data/test\"\n",
    "\n",
    "            with open(os.path.join(data_dir, str(task_id), \"keypath.json\"), 'r') as file:\n",
    "                keypaths = json.load(file)\n",
    "\n",
    "            for keypath in keypaths:\n",
    "                if match(history, keypath):\n",
    "                    success_list.append(task_id)\n",
    "                    break\n",
    "\n",
    "        print(len(success_list))\n",
    "        for succ in success_list:\n",
    "            if succ in ran:\n",
    "                sr_total += 1\n",
    "        task_total += len(eval_list)\n",
    "\n",
    "    return sr_total/task_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr(exp_name, ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plwsr(exp_name,ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path_count = 0\n",
    "for i in eval_list:\n",
    "    real_path_count += i[\"step_len\"]\n",
    "dataset_path_count = count_dataset_path()\n",
    "print(real_path_count)\n",
    "real_path_count/dataset_path_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20*100/count_dataset_path()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hab-mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
